{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#pip install -U folium","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Week 0 - actual 2nd course assignment starts here","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The postcodes for Toronto are avaible at [[https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M)]","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are several ways to get the data from the table such as beuatiful soup or reading the URL inot a dataframe.  The Capstone  instructions said d I can use any method so I simply selected and pasted the table area into a LibreOffice documnent then from that cut and pasted the data into a spreadsheet and saved as a CSV file.  This I then saved in my Kaggle data reared and opened into a Pandas frame.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"How ever we now have to clean the data by dropingpost codes not assigned and combining post code data listed twice usinf a comma.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/post-codes-toronto/pstalcodes.csv') #This is the raw data before cleaning\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have to remove any not assigned post codes","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = df[df.Borough != 'Not assigned']\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That looks good so far but need to find duplicate Post Code/s","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#looking for duplicate Post Codes\ndf[df['Post Code'].duplicated() == True]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### As you can see no duplicted post codes","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"****Looking for none assiged neighbour hoods[](http://)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.Neighbourhood == 'Not assigned']\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**** Again none so just maybe we have clean data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 103 rows 3 columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#In the case we want to display all the rows\n#pd.set_option('display.max_rows', df.shape[0]+1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Now we add coordinates from CSV# ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = pd.read_csv('/kaggle/input/coordinates-toronto/Coord.csv') #This is the raw data before cleaning\ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Add two new colomns to take the coordiantes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2 = df2.rename(columns={\"Postal Code\": \"Post Code\"}) #to match df name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['Latitude'] = df2['Postal Codes'].map(df2.set_index('Postal Codes')['Latitude'])\n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Merge after making headers the same","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(df, df2, on='Post Code', how='outer')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Week 1 Code Battle of the Neighbourhoods","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# MOVING ON WITH CODE","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"> Readign current cases of covid-19 in different boroughs","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df3 = pd.read_csv('/kaggle/input/toronto2/COVID-19Neighbourh.csv')\ndf3.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**43.651070, -79.347015    is coorinates of Toronto**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Change headers to match others","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df3 = df3.rename(columns={\"Neighbourhood Name\": \"Neighbourhood\"}) #to match df name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3 = df3.rename(columns={\"Rate per 100,000 people\": \"Rate\"}) #to match df name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n#using df3\ngroupedvalues=df3.groupby('Rate').sum().reset_index()\n\npal = sns.color_palette(\"Reds_d\", len(groupedvalues))\nrank = groupedvalues[\"Rate\"].argsort().argsort() \ntn = 'Neighbourhood'\nfirst_chars = tn[0:3]\ng=sns.barplot(x=tn,y='Rate',data=groupedvalues, palette=np.array(pal[::-1])[rank])\n\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = df3.sort_values(['Rate'])\nresult.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note the huge diference on the InfectionRate per 100,000 people","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Add the rate column to df","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def fuzzy_merge(df_1, df_2, key1, key2, threshold=90, limit=2):\n    \"\"\"\n    :param df_1: the left table to join\n    :param df_2: the right table to join\n    :param key1: key column of the left table\n    :param key2: key column of the right table\n    :param threshold: how close the matches should be to return a match, based on Levenshtein distance\n    :param limit: the amount of matches that will get returned, these are sorted high to low\n    :return: dataframe with boths keys and matches\n    \"\"\"\n    s = df_2[key2].tolist()\n\n    m = df_1[key1].apply(lambda x: process.extract(x, s, limit=limit))    \n    df_1['matches'] = m\n\n    m2 = df_1['matches'].apply(lambda x: ', '.join([i[0] for i in x if i[1] >= threshold]))\n    df_1['matches'] = m2\n\n    return df_1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Being clever**  Attempted to use\ndf = pd.merge(df, df3, on='Neighbourhood', how='outer')\ndf = df.dropna() #drop where neighbour hoods disagree \ndf\nand only got 10 neighbouhood matches so found a fuzzy function as shown below","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from fuzzywuzzy import fuzz\nfrom fuzzywuzzy import process\n\ndf = fuzzy_merge(df, df3, 'Neighbourhood','Neighbourhood', threshold=80)\n#df = pd.merge(df, df3, how='outer')\n#df = df.dropna() #drop where neighbour hoods disagree \ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*The above does not have the data in df3 added if you do we get*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# definition of the boundaries in the map\ndistrict_geo = r'/kaggle/input/toronto/Neighbourhoods.geojson'\n  \nprint (district_geo) #not used using circle size methos instead","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(df, df3, how='outer')\n# df = df.dropna() #drop where neighbourhoods disagree ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pip install -U folium\nimport folium\nT_COORDINATES = (43.651070, -79.347015)\nmapdata = df\n \n# for speed purposes\nMAX_RECORDS = 1000\n  \n# create empty map zoomed in on San Francisco\nmap = folium.Map(location=T_COORDINATES, zoom_start=12)\n \n# add a marker for every record in the filtered data, use a clustered view\n# Make an empty map\nm = folium.Map(location=T_COORDINATES, zoom_start=12)\n \n\n\n  \n#display(map)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only 10 neighbourhoods because the niebourhood name in the data taken from the Toronto site are not spelt the same so let us use Torontos dtat set instead","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df4 =  pd.read_csv('/kaggle/input/toronto3/Neighbourhoods.csv')\nlist(df4)\ndf4 = df4.drop(['X', 'Y', '_id'], axis=1)\ndf4.dropna()\ndf4.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df4 = df4.rename(columns={\"AREA_NAME\": \"Neighbourhood\"}) #to match df name\ndf4 = df4.rename(columns={\"LONGITUDE\": \"Longitude\"}) #to match df name\ndf4 = df4.rename(columns={\"LATITUDE\": \"Latitude\"}) #to match df name\ndf4.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df4['Neighbourhood']=df4['Neighbourhood'].str[:10]\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Because of (xx) number in text just compare first 8 characters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df3['Neighbourhood']=df3['Neighbourhood'].str[:10]\ndf3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df4 = pd.merge(df4, df3, on='Neighbourhood', how='outer')\n# df4 = df4.apply (pd.to_numeric, errors='coerce')\n\n#df4 = df4.dropna()\ndf4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(df4.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pip install -U folium\nimport folium\nT_COORDINATES = (43.651070, -79.347015)\n\nmapdata = df4\n\n \n# for speed purposes\nMAX_RECORDS = 1000\n  \n# create empty map zoomed in on Toronto\n#map = folium.Map(location=T_COORDINATES, zoom_start=12)\n \n# add a marker for every record in the filtered data, use a clustered view\n# Make an empty map\nvenues_map = folium.Map(location=T_COORDINATES, zoom_start=12)\n \n\n\n  \n# display(m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# I can add marker one by one on the map\nimport math\nfor i in range(0,len(mapdata)):    \n        location=[mapdata.iloc[i]['Latitude'], mapdata.iloc[i]['Longitude']]\n        # print (location[0])\n        if (location[0] > 20):\n            rate = mapdata.iloc[i]['Rate']\n            if (math.isnan(rate)):\n                #print(rate)\n                rate = 1\n            #print (location)\n            # print(rate)\n            folium.Circle(\n              location=[mapdata.iloc[i]['Latitude'], mapdata.iloc[i]['Longitude']],\n              popup=mapdata.iloc[i]['Neighbourhood'],\n              # radius=mapdata.iloc[i]['Rate']/1,\n              radius = rate,\n              color='crimson',\n              fill=True,\n              fill_color='crimson'\n       ).add_to(venues_map)\n#print(df4.shape)\n\n#display(venues_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import requests # library to handle requests\n# import pandas as pd # library for data analsysis\n# import numpy as np # library to handle data in a vectorized manner\nimport random # library for random number generation\n\n#!conda install -c conda-forge geopy --yes \n#from geopy.geocoders import Nominatim # module to convert an address into latitude and longitude values\n\n# libraries for displaying images\nfrom IPython.display import Image \nfrom IPython.core.display import HTML \n    \n# tranforming json file into a pandas dataframe library\nfrom pandas.io.json import json_normalize\n\n#!conda install -c conda-forge folium=0.5.0 --yes\n#import folium # plotting library\n\n#print('Folium installed')\nprint('Libraries imported.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CLIENT_ID = 'BCQ3KNRQKOHYNMOOLYSELTZ2CEJEIDTW1FCABZBDSHDXPMJ3' # My Foursquare ID\nCLIENT_SECRET = 'HJ1ZGT1RE2CYHPQGCAPNLNT42YHO3MCJZF3BTWL1ZUG4J3NX' # your Foursquare Secret\nVERSION = '20180323'\nLIMIT = 30\nprint('My credentails:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"address = '88 Boulton Ave, Toronto' \n\n#geolocator = Nominatim(user_agent=\"foursquare_agent\")\n#location = geolocator.geocode(address)\n#print(location.latitude )\n#latitude = location.latitude #43.66278703030303\n#longitude = location.longitude # -79.34818218181817\n\nlatitude = 43.66278703030303\nlongitude = -79.34818218181817\n\nprint(latitude, longitude)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"search_query = 'Park'\nradius = 1000\nprint(search_query + ' .... OK!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"url = 'https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll={},{}&v={}&query={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude, VERSION, search_query, radius, LIMIT)\nurl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = requests.get(url).json()\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# assign relevant part of JSON to venues\nvenues = results['response']['venues']\n\n# tranform venues into a dataframe\ndataframe = json_normalize(venues)\ndataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# keep only columns that include venue name, and anything that is associated with location\nfiltered_columns = ['name', 'categories'] + [col for col in dataframe.columns if col.startswith('location.')] + ['id']\ndataframe_filtered = dataframe.loc[:, filtered_columns]\n\n# function that extracts the category of the venue\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']\n\n# filter the category for each row\ndataframe_filtered['categories'] = dataframe_filtered.apply(get_category_type, axis=1)\n\n# clean column names by keeping only last term\ndataframe_filtered.columns = [column.split('.')[-1] for column in dataframe_filtered.columns]\n\ndataframe_filtered","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe_filtered.name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#venues_map = folium.Map(location=[latitude, longitude], zoom_start=13) # generate map centred around my first address\n\n# add a dark green circle marker to represent my first location\nfolium.CircleMarker(\n    [latitude, longitude],\n    radius=10,\n    color='darkgreen',\n    popup='First Location',\n    fill = True,\n    fill_color = 'darkgreen',\n    fill_opacity = 0.6\n).add_to(venues_map)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add the parks as blue circle markers\nfor lat, lng, label in zip(dataframe_filtered.lat, dataframe_filtered.lng, dataframe_filtered.categories):\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        color='blue',\n        popup=label,\n        fill = True,\n        fill_color='blue',\n        fill_opacity=0.6\n    ).add_to(venues_map)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ******NEXT start address****\n\n\n\n\n\n******","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"address = '489 Merton St, Toronto' \n\n#geolocator = Nominatim(user_agent=\"foursquare_agent\")\n#location = geolocator.geocode(address)\n#print(location.latitude )\n#latitude = location.latitude #43.66278703030303\n#longitude = location.longitude # -79.34818218181817\n#43.69897,-79.38174 Mertonn\n\nlatitude = 43.69897\nlongitude = -79.38174\n\nprint(latitude, longitude)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"search_query = 'Park'\nradius = 1000\nprint(search_query + ' .... OK!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"url = 'https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll={},{}&v={}&query={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude, VERSION, search_query, radius, LIMIT)\nurl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = requests.get(url).json()\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# assign relevant part of JSON to venues\nvenues = results['response']['venues']\n\n# tranform venues into a dataframe\ndataframe = json_normalize(venues)\ndataframe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# keep only columns that include venue name, and anything that is associated with location\nfiltered_columns = ['name', 'categories'] + [col for col in dataframe.columns if col.startswith('location.')] + ['id']\ndataframe_filtered = dataframe.loc[:, filtered_columns]\n\n# function that extracts the category of the venue\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']\n\n# filter the category for each row\ndataframe_filtered['categories'] = dataframe_filtered.apply(get_category_type, axis=1)\n\n# clean column names by keeping only last term\ndataframe_filtered.columns = [column.split('.')[-1] for column in dataframe_filtered.columns]\n\ndataframe_filtered","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe_filtered.name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#venues_map = folium.Map(location=[latitude, longitude], zoom_start=13) # generate map centred around my second address\n# add a rgreen circle marker to represent my first location\nfolium.CircleMarker(\n    [latitude, longitude],\n    radius=10,\n    color='green',\n    popup='Second Location',\n    fill = True,\n    fill_color = 'green',\n    fill_opacity = 0.6\n).add_to(venues_map)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add the parks as blue circle markers\nfor lat, lng, label in zip(dataframe_filtered.lat, dataframe_filtered.lng, dataframe_filtered.categories):\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        color='purple',\n        popup=label,\n        fill = True,\n        fill_color='purple',\n        fill_opacity=0.8\n    ).add_to(venues_map)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"venues_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}